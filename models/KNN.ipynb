{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hT_fcbnb1_Gv"
      },
      "source": [
        "# Importing Libraries and Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUW1cH-gzgrv"
      },
      "source": [
        "from math import sqrt\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uw6CgX-i-Ser"
      },
      "source": [
        "## IMPORT DATA HERE (TF-IDF TRANSFORMED SPARSE MATRIX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUIC6Vyh3aEM"
      },
      "source": [
        "# Buidling the Model\n",
        "K-Nearest Neighbors (KNN) is an unsupervised learning algorithm. It relies on calculating the distance between datapoints, as specified by a certain method (Mnhattan, Euclidean...). Next, it gets the neighbors with minimum distance, ie. those closest to the data point we want to classify.\n",
        "## Calculating Distance\n",
        "For this case we will calculate the Euclidean distance between the rows. Since we have a sparse matrix of normalized count values that we got from out TF-IDF Transformer, we could find the euclidean distance by taking the square-root of the difference squared of each word-count value across all the tweets.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZguCWqy64_6_"
      },
      "source": [
        "def euclidean_distance(tweet0, tweet1):\n",
        "  ## init distance to 0\n",
        "    distance = 0.0\n",
        "    ## loop through the word counts both tweets and take the\n",
        "    ##difference at each position\n",
        "    for i in range(len(tweet0)-1):\n",
        "        distance += (tweet0[i] - tweet1[i])**2\n",
        "    ## return the square-root of the squared distance\n",
        "    return sqrt(distance)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iukjnzcx5ubC"
      },
      "source": [
        "## Getting the Neighbors\n",
        "In this step, we use the distances from the previous step to see the closest k-neighbors to our datapoint."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7prqb_-H5riH"
      },
      "source": [
        "def get_neighbors(training_set, test_tweet, k):\n",
        "  ## init list of distances to store (tweet, distance) tuples\n",
        "    distances = list()\n",
        "    ## loop through tweets in the dataset and calculate distance to test_tweet\n",
        "    for tweet in training_set:\n",
        "        dist = euclidean_distance(test_tweet, tweet)\n",
        "        distances.append((tweet, dist))\n",
        "    ## sort the (tweet, distance) entries based on distance\n",
        "    distances.sort(key=lambda entry: entry[1])\n",
        "    ## Now we can get the neighbors based on the specified k\n",
        "    neighbors = list()\n",
        "    for i in range(k):\n",
        "        neighbors.append(distances[i][0])\n",
        "    return neighbors"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUo-JxEm7V5j"
      },
      "source": [
        "## Class Prediction\n",
        "Now that we have a way to calculate the distance and a method to get the neighbors using that distance measure, we can start making predictions. \n",
        "A prediction of class label `y` is basically the most frequent class of the k-neighbors closest to our test data-point. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccc0ETGM8GXQ"
      },
      "source": [
        "def predict_class(training_set, test_tweet, k):\n",
        "    ## getting the neighbors of our test data point\n",
        "    neighbors = get_neighbors(training_set, test_tweet, k)\n",
        "    ## getting the class labels of the k-neighbors\n",
        "    labels = [row[-1] for row in neighbors]\n",
        "    ## Now we make a prediction based on the most frequent class\n",
        "    prediction = max(set(labels), key=labels.count)\n",
        "    return prediction"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lup2Rzg82I3"
      },
      "source": [
        "## Testing on Fake data (Remove later)\n",
        "small test on fake dataset to make sure all is working fine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DC-UWK8G81ho",
        "outputId": "d509acc8-fa02-49e8-fceb-ccce1a9a06ba"
      },
      "source": [
        "dataset = [[2.7810836,2.550537003,0],\n",
        "    [1.465489372,2.362125076,0],\n",
        "    [3.396561688,4.400293529,0],\n",
        "    [1.38807019,1.850220317,0],\n",
        "    [3.06407232,3.005305973,0],\n",
        "    [7.627531214,2.759262235,1],\n",
        "    [5.332441248,2.088626775,1],\n",
        "    [6.922596716,1.77106367,1],\n",
        "    [8.675418651,-0.242068655,1],\n",
        "    [7.673756466,3.508563011,1]]\n",
        "tweet0 = dataset[0]\n",
        "i = 0\n",
        "for tweet in dataset:\n",
        "  distance = euclidean_distance(tweet0, tweet)\n",
        "  print(\"Distance between tweet0 and tweet%d is %.3f\" % (i,distance))\n",
        "  i+=1    "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance between tweet0 and tweet0 is 0.000\n",
            "Distance between tweet0 and tweet1 is 1.329\n",
            "Distance between tweet0 and tweet2 is 1.949\n",
            "Distance between tweet0 and tweet3 is 1.559\n",
            "Distance between tweet0 and tweet4 is 0.536\n",
            "Distance between tweet0 and tweet5 is 4.851\n",
            "Distance between tweet0 and tweet6 is 2.593\n",
            "Distance between tweet0 and tweet7 is 4.214\n",
            "Distance between tweet0 and tweet8 is 6.522\n",
            "Distance between tweet0 and tweet9 is 4.986\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEiYZsb99EH8",
        "outputId": "0df431b3-8831-4d49-e998-ab382a0e9241"
      },
      "source": [
        "neighbors = get_neighbors(dataset, tweet0, 3)\n",
        "for neighbor in neighbors:\n",
        "  print(neighbor)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.7810836, 2.550537003, 0]\n",
            "[3.06407232, 3.005305973, 0]\n",
            "[1.465489372, 2.362125076, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YRu0Rup_H2l",
        "outputId": "1e160972-0288-4e86-9549-25717bfcf5b2"
      },
      "source": [
        "prediction = predict_class(dataset, tweet0, 3)\n",
        "print('Expected Class: %d\\nGot Class: %d'% (dataset[0][-1], prediction))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected Class: 0\n",
            "Got Class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YH198lGx_6_0"
      },
      "source": [
        "Seems like it's working. \n",
        "#### TBD\n",
        "- [ ] Import data set as TF-IDF transformed matrix. (Or redo transformation then split to train, test, validate sets.  \n",
        "- [ ] Transform labels to numerical values (string to 1/0) (useful for max count extraction in neighbors generation) (faster to process than string comparison)    \n",
        "- [ ] Run model on dataset   \n",
        "- [ ] Create function to get prediction metrics"
      ]
    }
  ]
}